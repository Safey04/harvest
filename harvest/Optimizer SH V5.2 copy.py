# -*- coding: utf-8 -*-
"""Optmizer-SH-V5.2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j0U0_rTm_QhocQeX_5lDoatQMvaPqbZk
"""

pip install xlsxwriter pulp

pip install pulp

import pandas as pd
from pulp import LpProblem, LpVariable, LpBinary, lpSum, LpMaximize, LpContinuous, PULP_CBC_CMD

def add_house_dates_columns(df, duration_days=40, max_harvest_date=None):
    """
    Adds 'start_date', 'end_date', 'last_date', and 'max_harvest_date' columns to the input DataFrame
    without altering its row count. Calculations are based on each (Farm, House) group.

    Parameters:
    - df (pd.DataFrame): Original DataFrame with columns 'Farm', 'House', and 'date'.
    - duration_days (int): Days to add to start_date to compute last_date.
    - max_harvest_date (str or pd.Timestamp): Manually passed date for all rows.

    Returns:
    - pd.DataFrame: Original DataFrame with new date columns added.
    """
    df = df.copy()
    df['date'] = pd.to_datetime(df['date'])

    # Convert max_harvest_date to pd.Timestamp
    if max_harvest_date is not None:
        max_harvest_date = pd.to_datetime(max_harvest_date)

    # Get start and end dates per (Farm, House) group
    start_dates = df.groupby(['Farm', 'House'])['date'].transform('min')
    end_dates = df.groupby(['Farm', 'House'])['date'].transform('max')

    df['start_date'] = start_dates
    df['end_date'] = end_dates
    df['last_date'] = df['start_date'] + pd.to_timedelta(duration_days, unit='D')
    df['max_harvest_date'] = max_harvest_date

    return df

def remove_invalid_dates(df_with_date):
    """
    Removes rows where date > last_date or date > max_harvest_date.
    Returns two DataFrames:
      1. Cleaned DataFrame with valid rows
      2. Removed rows with a 'removal_reason' column
    """
    df = df_with_date.copy()

    # Boolean masks
    cond_date_gt_last = df['date'] > df['last_date']
    cond_date_gt_max = df['date'] > df['max_harvest_date']
    to_remove = cond_date_gt_last | cond_date_gt_max

    # Subset of rows to be removed
    removed_df = df[to_remove].copy()

    # Generate reasons only for removed rows
    reasons = []
    for gt_last, gt_max in zip(cond_date_gt_last[to_remove], cond_date_gt_max[to_remove]):
        reason = []
        if gt_last:
            reason.append("date > last_date")
        if gt_max:
            reason.append("date > max_harvest_date")
        reasons.append("; ".join(reason))

    removed_df['removal_reason'] = reasons

    # Cleaned DataFrame (rows to keep)
    cleaned_df = df[~to_remove].copy()

    return cleaned_df, removed_df

"""Expanding Average Weight range for unharvested houses"""

def compute_ready_sh(row, min_weight, max_weight):
    if row.get("SH_UN", 0) == 1:  # if SH_UN exists and equals 1
        return 1 if (min_weight - 0.05) <= row['AVG_Weight'] <= (max_weight + 0.05) else 0
    else:
        return 1 if min_weight <= row['AVG_Weight'] <= max_weight else 0

def flag_ready_avg_weight(
    df,
    min_weight,
    max_weight,
    harvest_type='SH'
):
    # Ensure date is datetime
    df['date'] = pd.to_datetime(df['date'])

    if harvest_type == 'SH':
      df['ready_SH'] = ready_df.apply(compute_ready_sh, axis=1, args=(min_weight, max_weight))
    elif harvest_type == 'Market':
            df['ready_Market'] = df['AVG_Weight'].apply(lambda x: 1 if min_weight <= x <= max_weight else 0)
    else:
            raise ValueError("Invalid harvest_type. Use 'SH' or 'Market'.")

    return df

import numpy as np
import pandas as pd

def flag_ready_daily_stock(
    df,
    min_stock,
    max_stock,
    harvest_type='SH',
    min_per_house=2000
):
    df['date'] = pd.to_datetime(df['date'])

    if harvest_type == 'SH':
        readySH_df = df[df['ready_SH'] == 1]
        stock_sum_by_date = readySH_df.groupby('date')['expected stock'].sum()
        flagged_dates = stock_sum_by_date[stock_sum_by_date >= min_per_house].index
        df['flag_day_sh'] = df['date'].isin(flagged_dates).astype(int)
    elif harvest_type == 'Market':
        readyM_df = df[df['ready_Market'] == 1]
        stock_mkt_by_date = readyM_df.groupby('date')['expected stock'].sum()
        flagged_mkt_dates = stock_mkt_by_date[stock_mkt_by_date >= min_stock].index
        df['flag_day_M'] = df['date'].isin(flagged_mkt_dates).astype(int)
    else:
        raise ValueError("Invalid harvest_type. Use 'SH' or 'Market'.")

    return df

def apply_harvest_updates(df_full, harvest_df):
    df = df_full.copy()
    df['expected stock'] = df['expected stock'].astype(int)
    df['farm_house_key'] = df['Farm'].astype(str) + "_" + df['House'].astype(str)
    df['date'] = pd.to_datetime(df['date'])
    harvest_df['date'] = pd.to_datetime(harvest_df['date'])

    for _, harvest in harvest_df.iterrows():
        farm = harvest['Farm']
        house = harvest['House']
        key = f"{farm}_{house}"
        date = harvest['date']
        harvested = harvest['harvest_stock']
        prev_stock = harvest['expected stock'] - harvested

        if harvested <= 0:
            continue

        # Drop current and previous rows for this house
        df = df[~((df['farm_house_key'] == key) & (df['date'] <= date))]

        # ‚úÖ If fully harvested, drop all future rows
        if prev_stock <= 0:
            df = df[df['farm_house_key'] != key]
            continue

        # Otherwise, update future rows
        mask = (df['farm_house_key'] == key) & (df['date'] > date)
        future_rows = df[mask].sort_values(by='date')

        for idx, row in future_rows.iterrows():
            mortality_rate = row.get('expectd Mortality Rate', 0)
            new_stock = prev_stock * (1 - mortality_rate) * 0.97  # Adjust for culls
            new_stock_rounded = int(round(new_stock))

            if new_stock_rounded > 0:
                df.at[idx, 'expected stock'] = new_stock_rounded
                prev_stock = new_stock
            else:
                df = df.drop(index=idx)
                break

    df = df[df['expected stock'] > 0].copy()
    return df

def apply_harvest_updates_only_once(df_full, harvest_df):
    df = df_full.copy()
    df['expected stock'] = df['expected stock'].astype(int)
    df['farm_house_key'] = df['Farm'].astype(str) + "_" + df['House'].astype(str)
    df['date'] = pd.to_datetime(df['date'])
    harvest_df['date'] = pd.to_datetime(harvest_df['date'])

    harvested_keys = set()

    for _, harvest in harvest_df.iterrows():
        farm = harvest['Farm']
        house = harvest['House']
        key = f"{farm}_{house}"
        date = harvest['date']
        harvested = harvest['harvest_stock']
        prev_stock = harvest['expected stock'] - harvested

        if harvested <= 0:
            continue

        harvested_keys.add(key)
        df = df[~((df['farm_house_key'] == key) & (df['date'] <= date))]

        mask = (df['farm_house_key'] == key) & (df['date'] > date)
        future_rows = df[mask].sort_values(by='date')

        for idx, row in future_rows.iterrows():
            mortality_rate = row.get('expectd Mortality Rate', 0)
            new_stock = prev_stock * (1 - mortality_rate) * 0.97
            new_stock_rounded = int(round(new_stock))

            if new_stock_rounded > 0:
                df.at[idx, 'expected stock'] = new_stock_rounded
                prev_stock = new_stock
            else:
                df = df.drop(index=idx)
                break

    for key in harvested_keys:
        df = df[df['farm_house_key'] != key]

    df = df[df['expected stock'] > 0].copy()
    return df

"""Changes to this loop to identify last elligibale day for harvest in case of only one house left behind will harvest all houses on this day"""

def SH_min_houses_uniform_extra_base(
    df_day,
    min_total_stock=70000,
    max_pct_per_house=0.30,   # fixed cap (no escalation)
    min_per_house=2000,
    pct_step=0.05,            # unused (kept for signature compatibility)
    pct_max=1.00              # ceiling (upper bound for fixed cap)
):
    import numpy as np
    import pandas as pd

    df0 = df_day.reset_index(drop=True).copy()
    need = {'Farm','date','House','AVG_Weight','expected stock','opportunity'}
    miss = need - set(df0.columns)
    if miss:
        raise ValueError(f"Missing columns: {miss}")

    # validity
    df0 = df0[(df0['AVG_Weight'] > 0) & (df0['expected stock'] > 0)].copy()
    if df0.empty:
        return df0.iloc[0:0]

    final_cap_pct = float(min(max_pct_per_house, pct_max))

    def build_selection_fixed(df_src, pct):
        df = df_src.copy()
        df['cap'] = np.minimum(
            np.floor(df['expected stock'] * pct).astype(int),
            df['expected stock'].astype(int)
        )

        # opp==1 must be feasible at this pct
        opp1 = df[df['opportunity'] == 1]
        if not opp1.empty and (opp1['cap'] < min_per_house).any():
            return None, 0

        df = df[df['cap'] >= min_per_house].copy()
        if df.empty:
            return None, 0

        # mandatory: all opp==1
        sel = df[df['opportunity'] == 1].copy()
        cap_sum = int(sel['cap'].sum()) if not sel.empty else 0

        # add minimal opp>1 until reaching min_total_stock if possible
        pool = df[df['opportunity'] > 1].sort_values(
            ['opportunity','AVG_Weight','cap'], ascending=[True, True, False]
        )
        for _, row in pool.iterrows():
            if cap_sum >= min_total_stock:
                break
            sel = pd.concat([sel, row.to_frame().T], ignore_index=True)
            cap_sum += int(row['cap'])

        return sel, cap_sum

    sel, cap_sum = build_selection_fixed(df0, final_cap_pct)
    if sel is None or sel.empty:
        return df0.iloc[0:0]

    # use fixed-cap selection
    sel = sel.copy()
    sel['cap'] = np.minimum(
        np.floor(sel['expected stock'] * final_cap_pct).astype(int),
        sel['expected stock'].astype(int)
    )

    achievable = int(sel['cap'].sum())
    T = min(int(min_total_stock), achievable)

    # per-house minimum
    n = len(sel)
    base_total = n * int(min_per_house)
    if base_total > T:
        T = base_total  # still ‚â§ achievable because cap ‚â• min_per_house per house

    # allocate: min + uniform % extra within residual caps, then top-up by lowest weight
    sel['harvest_stock'] = int(min_per_house)
    sel['residual_cap'] = (sel['cap'] - sel['harvest_stock']).clip(lower=0).astype(int)

    remaining = int(T - base_total)
    if remaining > 0:
        low, high = 0.0, final_cap_pct
        best_extra = np.zeros(n, dtype=int)
        exp = sel['expected stock'].to_numpy()
        res = sel['residual_cap'].to_numpy()

        for _ in range(60):
            mid = (low + high) / 2.0
            extra = np.floor(exp * mid).astype(int)
            extra = np.minimum(extra, res)
            if int(extra.sum()) <= remaining:
                best_extra = extra
                low = mid
            else:
                high = mid

        sel['harvest_stock'] += best_extra
        spill = remaining - int(best_extra.sum())
        if spill > 0:
            for i in sel.sort_values('AVG_Weight').index:
                if spill <= 0:
                    break
                used = int(sel.at[i, 'harvest_stock'] - min_per_house)
                can_add = int(sel.at[i, 'residual_cap'] - used)
                if can_add > 0:
                    add = min(can_add, spill)
                    sel.at[i, 'harvest_stock'] += add
                    spill -= add

    # finalize
    sel['harvest_stock'] = sel['harvest_stock'].astype(int)
    sel = sel[sel['harvest_stock'] > 0].copy()
    sel['net_meat'] = sel['harvest_stock'] * sel['AVG_Weight']
    sel['selected'] = 1
    sel['harvest_type'] = 'SH'
    sel['final_pct_per_house'] = sel['harvest_stock'].astype(float) / sel['expected stock'].astype(float)
    sel['cap_pct_per_house']   = sel['cap'].astype(float) / sel['expected stock'].astype(float)

    cols = ['Farm','date','House','age','expected Mortality','expected stock',
            'expectd Mortality Rate','AVG_Weight','opportunity','selected',
            'harvest_stock','net_meat','harvest_type','final_pct_per_house','cap_pct_per_house']
    cols = [c for c in cols if c in sel.columns]
    return sel[cols]

def SH_min_houses_uniform_extra_pct(
    df_day,
    min_total_stock=70000,
    max_pct_per_house=0.30,   # starting cap
    min_per_house=2000,
    pct_step=0.05,            # increment
    pct_max=1.00              # ceiling
):
    import numpy as np
    import pandas as pd

    df0 = df_day.reset_index(drop=True).copy()
    need = {'Farm','date','House','AVG_Weight','expected stock','opportunity'}
    miss = need - set(df0.columns)
    if miss:
        raise ValueError(f"Missing columns: {miss}")

    # validity
    df0 = df0[(df0['AVG_Weight'] > 0) & (df0['expected stock'] > 0)].copy()
    if df0.empty:
        return df0.iloc[0:0]

    def build_selection(df_src, pct):
        df = df_src.copy()
        df['cap'] = np.minimum(
            np.floor(df['expected stock'] * pct).astype(int),
            df['expected stock'].astype(int)
        )
        # opp==1 must be selectable at this pct
        opp1 = df[df['opportunity'] == 1]
        if not opp1.empty and (opp1['cap'] < min_per_house).any():
            return None, 0

        df = df[df['cap'] >= min_per_house].copy()
        if df.empty:
            return None, 0

        # mandatory: all opp==1
        sel = df[df['opportunity'] == 1].copy()
        cap_sum = int(sel['cap'].sum()) if not sel.empty else 0

        # add minimal opp>1 needed (opportunity asc, weight asc, cap desc)
        pool = df[df['opportunity'] > 1].sort_values(
            ['opportunity','AVG_Weight','cap'], ascending=[True, True, False]
        )
        for _, row in pool.iterrows():
            if cap_sum >= min_total_stock:
                break
            sel = pd.concat([sel, row.to_frame().T], ignore_index=True)
            cap_sum += int(row['cap'])

        return sel, cap_sum

    # escalate pct until target feasible or ceiling reached
    pct = float(max_pct_per_house)
    best_sel, best_cap = None, 0
    while pct <= pct_max + 1e-12:
        sel, cap_sum = build_selection(df0, pct)
        if sel is not None:
            best_sel, best_cap = sel, cap_sum
            if cap_sum >= min_total_stock:
                break
        pct = round(min(pct_max, pct + pct_step), 6)

    # If 100% still cannot reach target -> take maximum available weight (take everything eligible)
    if best_cap < min_total_stock:
        df_full = df0.copy()
        df_full['cap'] = np.floor(df_full['expected stock']).astype(int)

        # opp==1 houses must be feasible
        opp1 = df_full[df_full['opportunity'] == 1]
        if not opp1.empty and (opp1['cap'] < min_per_house).any():
            return df0.iloc[0:0]

        df_full = df_full[df_full['cap'] >= min_per_house].copy()
        if df_full.empty:
            return df0.iloc[0:0]

        df_full['harvest_stock'] = df_full['cap'].astype(int)
        df_full['net_meat'] = df_full['harvest_stock'] * df_full['AVG_Weight']
        df_full['selected'] = 1
        df_full['harvest_type'] = 'SH'
        df_full['final_pct_per_house'] = df_full['harvest_stock'] / df_full['expected stock']
        df_full['cap_pct_per_house'] = 1.0

        cols = ['Farm','date','House','age','expected Mortality','expected stock',
                'expectd Mortality Rate','AVG_Weight','opportunity','selected',
                'harvest_stock','net_meat','harvest_type','final_pct_per_house','cap_pct_per_house']
        cols = [c for c in cols if c in df_full.columns]
        return df_full[cols]

    # Otherwise proceed with uniform-extra allocation using the best selection
    sel = best_sel.copy()
    sel['cap'] = np.minimum(
        np.floor(sel['expected stock'] * min(pct, pct_max)).astype(int),
        sel['expected stock'].astype(int)
    )

    achievable = int(sel['cap'].sum())
    T = min_total_stock if achievable >= min_total_stock else achievable

    # per-house minimum
    n = len(sel)
    base_total = n * int(min_per_house)
    if base_total > T:
        T = base_total

    # allocate: min + uniform % extra within residual caps, then top-up by lowest weight
    sel['harvest_stock'] = int(min_per_house)
    sel['residual_cap'] = (sel['cap'] - sel['harvest_stock']).clip(lower=0).astype(int)

    remaining = int(T - base_total)
    if remaining > 0:
        low, high = 0.0, float(min(pct, pct_max))
        best_extra = np.zeros(n, dtype=int)
        exp = sel['expected stock'].to_numpy()
        res = sel['residual_cap'].to_numpy()

        for _ in range(60):
            mid = (low + high) / 2.0
            extra = np.floor(exp * mid).astype(int)
            extra = np.minimum(extra, res)
            if int(extra.sum()) <= remaining:
                best_extra = extra
                low = mid
            else:
                high = mid

        sel['harvest_stock'] += best_extra
        spill = remaining - int(best_extra.sum())
        if spill > 0:
            for i in sel.sort_values('AVG_Weight').index:
                if spill <= 0:
                    break
                used = int(sel.at[i, 'harvest_stock'] - min_per_house)
                can_add = int(sel.at[i, 'residual_cap'] - used)
                if can_add > 0:
                    add = min(can_add, spill)
                    sel.at[i, 'harvest_stock'] += add
                    spill -= add

    # finalize
    sel['harvest_stock'] = sel['harvest_stock'].astype(int)
    sel = sel[sel['harvest_stock'] > 0].copy()
    sel['net_meat'] = sel['harvest_stock'] * sel['AVG_Weight']
    sel['selected'] = 1
    sel['harvest_type'] = 'SH'
    sel['final_pct_per_house'] = sel['harvest_stock'].astype(float) / sel['expected stock'].astype(float)
    sel['cap_pct_per_house']   = sel['cap'].astype(float) / sel['expected stock'].astype(float)

    cols = ['Farm','date','House','age','expected Mortality','expected stock',
            'expectd Mortality Rate','AVG_Weight','opportunity','selected',
            'harvest_stock','net_meat','harvest_type','final_pct_per_house','cap_pct_per_house']
    cols = [c for c in cols if c in sel.columns]
    return sel[cols]

def SH_all_houses_uniform_extra(
    df_day,
    min_total_stock=70000,
    max_pct_per_house=0.30,   # fixed cap (no escalation)
    min_per_house=2000,
    pct_step=0.05,            # unused (kept for signature compatibility)
    pct_max=1.00              # ceiling
):
    import numpy as np
    import pandas as pd

    df0 = df_day.reset_index(drop=True).copy()
    need = {'Farm','date','House','AVG_Weight','expected stock'}
    miss = need - set(df0.columns)
    if miss:
        raise ValueError(f"Missing columns: {miss}")

    # validity
    df0 = df0[(df0['AVG_Weight'] > 0) & (df0['expected stock'] > 0)].copy()
    if df0.empty:
        return df0.iloc[0:0]

    def selectable_at_pct(df_src, pct):
        df = df_src.copy()
        df['cap'] = np.minimum(
            np.floor(df['expected stock'] * pct).astype(int),
            df['expected stock'].astype(int)
        )
        df = df[df['cap'] >= min_per_house].copy()
        return df

    # FIXED pct (no loop)
    final_cap_pct = float(min(max_pct_per_house, pct_max))
    sel = selectable_at_pct(df0, final_cap_pct)
    if sel is None or sel.empty:
        return df0.iloc[0:0]

    # target is min(min_total_stock, achievable at fixed pct)
    achievable = int(sel['cap'].sum())
    T = min(int(min_total_stock), achievable)

    # per-house minimum
    n = len(sel)
    base_total = n * int(min_per_house)
    if base_total > T:
        T = base_total  # still ‚â§ achievable because cap ‚â• min_per_house per house

    # allocate: min + uniform % extra within residual caps, then top-up by lowest weight
    sel['harvest_stock'] = int(min_per_house)
    sel['residual_cap'] = (sel['cap'] - sel['harvest_stock']).clip(lower=0).astype(int)

    remaining = int(T - base_total)
    if remaining > 0:
        low, high = 0.0, final_cap_pct
        best_extra = np.zeros(n, dtype=int)
        exp = sel['expected stock'].to_numpy()
        res = sel['residual_cap'].to_numpy()

        for _ in range(60):
            mid = (low + high) / 2.0
            extra = np.floor(exp * mid).astype(int)
            extra = np.minimum(extra, res)
            if int(extra.sum()) <= remaining:
                best_extra = extra
                low = mid
            else:
                high = mid

        sel['harvest_stock'] += best_extra
        spill = remaining - int(best_extra.sum())
        if spill > 0:
            for i in sel.sort_values('AVG_Weight').index:
                if spill <= 0:
                    break
                used = int(sel.at[i, 'harvest_stock'] - min_per_house)
                can_add = int(sel.at[i, 'residual_cap'] - used)
                if can_add > 0:
                    add = min(can_add, spill)
                    sel.at[i, 'harvest_stock'] += add
                    spill -= add

    # finalize
    sel['harvest_stock'] = sel['harvest_stock'].astype(int)
    sel = sel[sel['harvest_stock'] > 0].copy()
    sel['net_meat'] = sel['harvest_stock'] * sel['AVG_Weight']
    sel['selected'] = 1
    sel['harvest_type'] = 'SH'
    sel['final_pct_per_house'] = sel['harvest_stock'].astype(float) / sel['expected stock'].astype(float)
    sel['cap_pct_per_house']   = sel['cap'].astype(float) / sel['expected stock'].astype(float)

    cols = ['Farm','date','House','age','expected Mortality','expected stock',
            'expectd Mortality Rate','AVG_Weight','selected',
            'harvest_stock','net_meat','harvest_type','final_pct_per_house','cap_pct_per_house']
    cols = [c for c in cols if c in sel.columns]
    return sel[cols]

def SH_run_daily_harvest_loop(df_input, optimizer_fn, start_date,
                              min_weight, max_weight,
                              min_stock, max_stock,
                              num_days=7, max_pct_per_house=0.3, min_per_house=2000):

    import pandas as pd

    df = df_input.copy()
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df_all = df.copy()
    full_results = []
    start_date = pd.to_datetime(start_date)
    loop_start = start_date.normalize()

    for day_offset in range(num_days):
        current_date = start_date + pd.Timedelta(days=day_offset)
        cur_day = current_date.normalize()

        # Skip Thursdays
        if current_date.weekday() == 3:
            print(f"‚è© Skipping harvest on {current_date.date()} (Thursday).")
            continue

        print(f"\nüîÅ Running harvest for {current_date.date()}")

        # Re-flag SH readiness on the evolving df
        df = flag_ready_avg_weight(df, min_weight, max_weight, 'SH')
        df = flag_ready_daily_stock(df, min_stock, max_stock, 'SH', min_per_house)
        df['date'] = pd.to_datetime(df['date'], errors='coerce')

        # Current eligible set
        in_df = df[(df['flag_day_sh'] == 1) & (df['ready_SH'] == 1)].copy()
        if in_df.empty:
            print("‚õî No eligible houses at all ‚Äî skipping.")
            continue

        in_df['date'] = pd.to_datetime(in_df['date'], errors='coerce')
        in_df = in_df.sort_values(['Farm','House','date'], ascending=[True, True, False])

        # Opportunity counting that skips Thursdays
        is_not_thu = in_df['date'].dt.dayofweek != 3
        in_df.loc[:, 'opportunity'] = (
            is_not_thu.astype(int)
            .groupby([in_df['Farm'], in_df['House']])
            .cumsum()
            .where(is_not_thu, other=pd.NA)
            .astype('Int64')
        )

        # Today‚Äôs rows (normalize compare)
        day_df = in_df[in_df['date'].dt.normalize() == cur_day].copy()
        if day_df.empty:
            print(f"üì≠ No houses to harvest on {current_date.date()} ‚Äî skipping.")
            continue

        # -------- dynamic penultimate-all-houses check (no global pre-scan) --------
        elig_no_thu = in_df[in_df['date'].dt.dayofweek != 3].copy()
        last_date = elig_no_thu['date'].dt.normalize().max()
        use_all_houses = False
        if pd.notna(last_date):
            last_rows = elig_no_thu[elig_no_thu['date'].dt.normalize() == last_date]
            # if the *last* eligible day has exactly one Farm-House
            if not last_rows.empty and last_rows[['Farm','House']].drop_duplicates().shape[0] == 1:
                fh = last_rows[['Farm','House']].drop_duplicates().iloc[0]
                # find the closest earlier day where this same FH also appears
                earlier = elig_no_thu[
                    (elig_no_thu['Farm'] == fh['Farm']) &
                    (elig_no_thu['House'] == fh['House']) &
                    (elig_no_thu['date'].dt.normalize() < last_date)
                ]
                if not earlier.empty:
                    penultimate = earlier['date'].dt.normalize().max()
                    # if today is that penultimate day, switch to all-houses optimizer
                    if cur_day == penultimate:
                        use_all_houses = True
                        print(f"‚ñ∂ Using SH_all_houses_uniform_extra on {current_date.date()} (penultimate day rule).")
        # --------------------------------------------------------------------------

        # Run optimizer
        if use_all_houses:
            result = SH_all_houses_uniform_extra(
                day_df,
                max_pct_per_house=max_pct_per_house,
                min_total_stock=min_stock,
                min_per_house=min_per_house
            )
        else:
          if "NF" in day_df.columns and (day_df["NF"] == 1).any():
            result = SH_min_houses_uniform_extra_pct(
                day_df,
                max_pct_per_house=max_pct_per_house,
                min_total_stock=min_stock,
                min_per_house=min_per_house
            )
          else:
              result = optimizer_fn(
                day_df,
                max_pct_per_house=max_pct_per_house,
                min_total_stock=min_stock,
                min_per_house=min_per_house)


        if result.empty:
            print(f"‚ö†Ô∏è Optimizer returned no harvest for {current_date.date()} ‚Äî skipping.")
            continue

        # Keep only today‚Äôs rows
        result['date'] = pd.to_datetime(result['date'], errors='coerce')
        result = result[result['date'].dt.normalize() == cur_day]
        if result.empty:
            print(f"‚ùå Optimizer returned rows, but none match {current_date.date()}. Skipping.")
            continue

        # Apply updates
        full_results.append(result)
        df_all = apply_harvest_updates(df_all, result)
        df = apply_harvest_updates_only_once(df, result)

        # Early stop if no future rows remain
        if df.empty:
            print("‚úÖ No future rows after updates. Ending loop.")
            break
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        if not df['date'].dt.normalize().gt(cur_day).any():
            print("‚úÖ No future rows after updates. Ending loop.")
            break

    harvest_df = pd.concat(full_results, ignore_index=True) if full_results else pd.DataFrame()
    return harvest_df, df_all

"""Check Scenerios untill the last elligible day"""

def SH_run_multiple_harvest_starts(df_input,
                                   optimizer_fn,
                                   min_weight, max_weight,
                                   min_stock, max_stock,
                                   max_pct_per_house=0.3, min_per_house=2000):
    import pandas as pd

    df_base = df_input.copy()
    df_base['date'] = pd.to_datetime(df_base['date'], errors='coerce')

    results_by_start_day, all_updated_dfs = {}, {}

    # Eligible non-Thursday start days
    scan = df_base.copy()
    scan = flag_ready_avg_weight(scan, min_weight, max_weight, 'SH')
    scan = flag_ready_daily_stock(scan, min_stock, max_stock, 'SH', min_per_house)
    scan['date'] = pd.to_datetime(scan['date'], errors='coerce')

    elig_mask = (scan['flag_day_sh'] == 1) & (scan['ready_SH'] == 1) & (scan['date'].dt.dayofweek != 3)
    elig_days = sorted(scan.loc[elig_mask, 'date'].dt.normalize().dropna().unique().tolist())
    if not elig_days:
        return {}, {}

    last_eligible_day = pd.to_datetime(elig_days[-1])

    for start_day in elig_days:
        start_day = pd.to_datetime(start_day)
        num_days = int((last_eligible_day - start_day).days) + 1
        if num_days <= 1:
            continue

        print(f"üîÅ Running harvest loop starting at {start_day.date()}")
        harvest_df, updated_df = SH_run_daily_harvest_loop(
            df_input=df_base.copy(),
            optimizer_fn=optimizer_fn,
            start_date=start_day,
            min_weight=min_weight,
            max_weight=max_weight,
            min_stock=min_stock,
            max_stock=max_stock,
            num_days=num_days,
            max_pct_per_house=max_pct_per_house,
            min_per_house=min_per_house
        )

        if harvest_df.empty:
            print(f"‚õî No harvest generated for start date {start_day.date()}")
            if start_day == last_eligible_day:
                print("üõë Reached last eligible start day. Stopping.")
                break
            continue

        results_by_start_day[start_day.date()] = {
            'harvest': harvest_df,
            'updated_df': updated_df
        }
        all_updated_dfs[start_day.date()] = updated_df.copy()

    return results_by_start_day, all_updated_dfs

"""Get the best scenerio thatt has the maximum harvest stock"""

def get_best_harvest_stock_plan(plan_dict):
    """
    Finds the best plan (by total harvested stock) from a dict with date keys and {'harvest', 'updated_df'} values.

    Parameters:
        plan_dict (dict): {
            date_obj: {
                'harvest': DataFrame,
                'updated_df': DataFrame
            }
        }

    Returns:
        best_date (datetime.date): Date of the best harvest plan.
        best_harvest_df (pd.DataFrame): Harvest dataframe with highest total harvest stock.
        best_updated_df (pd.DataFrame): Corresponding updated dataframe.
        sorted_summary (dict): {date: total_harvest_stock} sorted descending.
    """
    summary = {}

    for date_key, data in plan_dict.items():
        harvest_df = data.get('harvest')
        if isinstance(harvest_df, pd.DataFrame) and not harvest_df.empty and 'harvest_stock' in harvest_df.columns:
            total_stock = harvest_df['harvest_stock'].sum()
            summary[date_key] = total_stock

    if not summary:
        print("‚ö†Ô∏è No valid harvest plans with harvest_stock found.")
        return None, None, None, {}

    # Sort descending by total harvested stock
    sorted_summary = dict(sorted(summary.items(), key=lambda item: item[1], reverse=True))
    best_date = next(iter(sorted_summary))
    best_harvest_df = plan_dict[best_date]['harvest']
    best_updated_df = plan_dict[best_date]['updated_df']

    return best_date, best_harvest_df, best_updated_df, sorted_summary

import pandas as pd
import matplotlib.pyplot as plt

def summarize_harvest_plans(plan_dict):
    summary_rows = []

    for date_key, plan in plan_dict.items():
        df = plan.get('harvest')
        if df is None or df.empty or 'net_meat' not in df.columns:
            continue

        plan_name = f"harvest_{date_key.strftime('%Y%m%d')}"
        start_date = df['date'].min().date()
        end_date = df['date'].max().date()
        total_days = (end_date - start_date).days + 1
        total_net_meat = df['net_meat'].sum()
        total_stock = df['harvest_stock'].sum()
        unique_houses = df[['Farm', 'House']].drop_duplicates().shape[0]

        summary_rows.append({
            'plan_name': plan_name,
            'start_date': start_date,
            'end_date': end_date,
            'number_of_days': total_days,
            'number_of_unique_houses': unique_houses,
            'total_net_meat': total_net_meat,
            'total_stock': total_stock
        })

    summary_df = pd.DataFrame(summary_rows).sort_values(by='total_stock', ascending=False)
    return summary_df

def build_daily_summary(harvest_plans_dict):
    combined = []

    for plan in harvest_plans_dict.values():
        df = plan.get('harvest')
        if df is not None and not df.empty:
            combined.append(df[['date', 'harvest_stock', 'net_meat']])

    if not combined:
        return pd.DataFrame(columns=['date', 'total_harvest_stock', 'total_net_meat'])

    all_data = pd.concat(combined)
    summary = all_data.groupby('date', as_index=False).agg({
        'harvest_stock': 'sum',
        'net_meat': 'sum'
    })

    summary.rename(columns={
        'harvest_stock': 'total_harvest_stock',
        'net_meat': 'total_net_meat'
    }, inplace=True)

    return summary

"""Optimizer for all dates except last elligible date that aim to minimize the number of harvested houses as long as they can be harvested in another day

Last_day optimizer

Preparing Input Dataframe first for Slaughter House Harvest
Removing all predicted dates that pass each house last harvest date or end of the cycle date.
"""

df = pd.read_excel("poultry_weight_prediction.xlsx", sheet_name="Original Data")

df_with_dates= add_house_dates_columns(df, duration_days=40, max_harvest_date='2025-05-27')

cleaned_df, removed_df = remove_invalid_dates(df_with_dates)

ready_df = cleaned_df.drop(columns=['start_date', 'end_date', 'last_date', 'max_harvest_date'])

"""Calculate expected weight after removing 3% for Culls."""

ready_df['expected stock'] = ready_df['expected stock'] * 0.97
ready_df['expected stock'] = ready_df['expected stock'].round(0).astype(int)

unique_pairs = ready_df[['Farm', 'House']].drop_duplicates()

"""Run Slaughter House Harvest Plan Base Case"""

results_by_start_day_SH, all_updated_dfs_SH = SH_run_multiple_harvest_starts(df_input=ready_df,
    optimizer_fn=SH_min_houses_uniform_extra_base,
    min_weight=1.55,
    max_weight=1.70,
    min_stock=30000,
    max_stock=30000,
    max_pct_per_house=0.3,
                                                                             min_per_house=2000

)

"""Check Best Plan for the base case"""

best_base_date, best_base_plan_df, best_base_updated_df, sorted_net_meat_dict_base = get_best_harvest_stock_plan(results_by_start_day_SH)

"""compare the harvest houses VS Input Data to be harvested"""

SH_df = flag_ready_avg_weight(ready_df, 1.55, 1.7, 'SH')
SH_df = flag_ready_daily_stock(SH_df, 30000, 30000, 'SH', 2000)
SH_df = SH_df[(SH_df['flag_day_sh'] == 1) & (SH_df['ready_SH'] == 1)]
SH_df = SH_df.sort_values(['Farm','House','date'], ascending=[True, True, False])

is_not_thu = SH_df['date'].dt.dayofweek != 3  # Thu=3
SH_df.loc[:, 'opportunity'] = (
      is_not_thu.astype(int)
      .groupby([SH_df['Farm'], SH_df['House']])
      .cumsum()                                  # counts only non-Thu rows
      .where(is_not_thu, other=pd.NA)            # Thursdays get NA; use 0 if you prefer
      .astype('Int64')
    )

unique_pairs = SH_df[['Farm', 'House']].drop_duplicates()
harvested_pairs = best_base_plan_df[['Farm', 'House']].drop_duplicates()

# Perform anti-join to get pairs in ready_df but not in best_plan_df
missing_pairs = unique_pairs.merge(harvested_pairs, on=['Farm', 'House'], how='left', indicator=True)
missing_pairs = missing_pairs[missing_pairs['_merge'] == 'left_only'].drop(columns=['_merge'])
missing_pairs["reason"] = "Only One Day to harvest on a Vacation"

print(missing_pairs)

mp_df = pd.DataFrame(missing_pairs, columns=['Farm','House','reason'])
SH_missing = SH_df.merge(mp_df, on=['Farm','House'], how='inner')
SH_missing

SH_missing.to_excel("base_Unharvest-SH-Reasons.xlsx", index=False)

best_base_plan_df.to_excel("SlaughterHouseHarvestPlan_base.xlsx", index=False)

SH_df.to_excel("SlaughterHouseBase-Input.xlsx", index=False)

mp_df = pd.DataFrame(missing_pairs, columns=['Farm','House','reason'])
SH_missing = SH_df.merge(mp_df, on=['Farm','House'], how='inner')
# min_stock is a scalar (int)
min_stock = int(30000)#to be changed by the min_total_stock for the SH harvest

daily = best_base_plan_df.groupby('date', as_index=False)['harvest_stock'].sum()

pending_days = pd.DataFrame({
    'date': daily['date'],
    'pending_SH': (daily['harvest_stock'] < min_stock).astype(int),  # 1 if less than min_stock, else 0
    'pendin_stock': (min_stock - daily['harvest_stock']).astype(int) # can be negative if over min_stock
})
pending_days= pending_days[pending_days['pending_SH'] == 1]
pending_days

pending_days.to_excel("Unfulfilled_days_base.xlsx", index=False)

"""Scenerio 1: Average Weights Range Expending"""

missing_set = set(zip(missing_pairs['Farm'], missing_pairs['House']))

# Create SH_UN flag in ready_df
ready_df['SH_UN'] = [
    1 if (farm, house) in missing_set else 0
    for farm, house in zip(ready_df['Farm'], ready_df['House'])
]

"""Re-run Harvest with the average weight range expension"""

results_by_start_day_SH, all_updated_dfs_SH = SH_run_multiple_harvest_starts(df_input=ready_df,
    optimizer_fn=SH_min_houses_uniform_extra_base,
    min_weight=1.55,
    max_weight=1.70,
    min_stock=30000,
    max_stock=30000,
    max_pct_per_house=0.3,
                                                                             min_per_house=2000

)

best_sc_weight_date, best_sc_weight_plan_df, best_sc_weight_updated_df, sorted_net_meat_dict_sc_weight = get_best_harvest_stock_plan(results_by_start_day_SH)

harvested_pairs = best_sc_weight_plan_df[['Farm', 'House']].drop_duplicates()

# Perform anti-join to get pairs in ready_df but not in best_plan_df
missing_pairs = unique_pairs.merge(harvested_pairs, on=['Farm', 'House'], how='left', indicator=True)
missing_pairs = missing_pairs[missing_pairs['_merge'] == 'left_only'].drop(columns=['_merge'])
missing_pairs["reason"] = "Only One Day to harvest on a Vacation"

print(missing_pairs)

mp_df = pd.DataFrame(missing_pairs, columns=['Farm','House','reason'])
SH_missing = SH_df.merge(mp_df, on=['Farm','House'], how='inner')
SH_missing.to_excel("SC_Weight_Unharvest-SH-Reasons.xlsx", index=False)

best_sc_weight_plan_df.to_excel("SlaughterHouseHarvestPlan_SC_Weight.xlsx", index=False)

min_stock = int(30000) #to be changed by the min_total_stock for the SH harvest

daily = best_sc_weight_plan_df.groupby('date', as_index=False)['harvest_stock'].sum()

pending_days = pd.DataFrame({
    'date': daily['date'],
    'pending_SH': (daily['harvest_stock'] < min_stock).astype(int),  # 1 if less than min_stock, else 0
    'pendin_stock': (min_stock - daily['harvest_stock']).astype(int) # can be negative if over min_stock
})
pending_days= pending_days[pending_days['pending_SH'] == 1]
pending_days

pending_days_houses = best_sc_weight_plan_df.merge(
    pending_days[['date','pending_SH']],
    on='date',
    how='inner'
)[['date','Farm','House','pending_SH']]
pending_days_houses

subset = pending_days_houses[pending_days_houses.index > 0]

# count unique Farm‚ÄìHouse pairs in that subset
unique_pairs_NF = subset[['Farm','House']].drop_duplicates()

if len(unique_pairs_NF) == 1:
    NF_rows = subset
else:
    NF_rows = pd.DataFrame()  # empty if more than one unique pair
NF_rows

NF_rows.to_excel("Plan_SC_Weight_Ungulfilled_Houses_rows.xlsx", index=False)

ready_df["date"] = pd.to_datetime(ready_df["date"])
NF_rows["date"] = pd.to_datetime(NF_rows["date"])

# add NF column default 0
ready_df["NF"] = 0

# build set of tuples to match
keys = set(zip(NF_rows["date"], NF_rows["Farm"], NF_rows["House"]))

# flag rows with matching triple
ready_df.loc[
    ready_df.set_index(["date","Farm","House"]).index.isin(keys),
    "NF"
] = 1

"""Running Harvest Scenerio to fulfill Unfulfilled days"""

results_by_start_day_SH, all_updated_dfs_SH = SH_run_multiple_harvest_starts(df_input=ready_df,
    optimizer_fn=SH_min_houses_uniform_extra_base,
    min_weight=1.55,
    max_weight=1.70,
    min_stock=30000,
    max_stock=30000,
    max_pct_per_house=0.3,
                                                                             min_per_house=2000

)

best_sc_pct_date, best_sc_pct_plan_df, best_sc_pct_updated_df, sorted_net_meat_dict_sc_pct = get_best_harvest_stock_plan(results_by_start_day_SH)

best_sc_pct_plan_df.to_excel("SlaughterHouseHarvestPlan_SC_PCT.xlsx", index=False)

min_stock = int(30000) #to be changed by the min_total_stock for the SH harvest

daily = best_sc_pct_plan_df.groupby('date', as_index=False)['harvest_stock'].sum()

pending_days = pd.DataFrame({
    'date': daily['date'],
    'pending_SH': (daily['harvest_stock'] < min_stock).astype(int),  # 1 if less than min_stock, else 0
    'pendin_stock': (min_stock - daily['harvest_stock']).astype(int) # can be negative if over min_stock
})
pending_days= pending_days[pending_days['pending_SH'] == 1]
pending_days

pending_days_houses = best_sc_pct_plan_df.merge(
    pending_days[['date','pending_SH']],
    on='date',
    how='inner'
)[['date','Farm','House','pending_SH']]
pending_days_houses

subset = pending_days_houses[pending_days_houses.index > 0]

# count unique Farm‚ÄìHouse pairs in that subset
unique_pairs_NF = subset[['Farm','House']].drop_duplicates()

if len(unique_pairs_NF) == 1:
    NF_rows = subset
else:
    NF_rows = pd.DataFrame()  # empty if more than one unique pair
NF_rows

NF_rows.to_excel("Plan_SC_PCT_Ungulfilled_Houses_rows.xlsx", index=False)

best_sc_pct_plan_df[best_sc_pct_plan_df['final_pct_per_house']>0.3] #need to be replaced by the actual variable and exported into a new file